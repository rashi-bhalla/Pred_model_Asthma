{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import where\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "import scipy\n",
    "import sklearn\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn import linear_model\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE\n",
    "from scipy import stats\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import smote_variants as sv\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm10 = pd.read_csv(os.path.join(dataset_dir, 'pm10_testing.csv'))\n",
    "df_bc = pd.read_csv(os.path.join(dataset_dir, 'bc_testing.csv'))\n",
    "df_ozone = pd.read_csv(os.path.join(dataset_dir, 'ozone_testing.csv'))\n",
    "df_no = pd.read_csv(os.path.join(dataset_dir, 'no_testing.csv'))\n",
    "df_uv = pd.read_csv(os.path.join(dataset_dir, 'uv_testing.csv'))\n",
    "df_pm2 = pd.read_csv(os.path.join(dataset_dir, 'pm2_testing.csv'))\n",
    "df_temp = pd.read_csv(os.path.join(dataset_dir, 'temp_testing.csv'))\n",
    "df_wind = pd.read_csv(os.path.join(dataset_dir, 'wind_testing.csv'))\n",
    "data_hosp = pd.read_csv(os.path.join(dataset_dir, 'hosp_withoutcbu_auck.csv'))\n",
    "df_RH = pd.read_csv(os.path.join(dataset_dir, 'RH_testing.csv'))\n",
    "df_pres = pd.read_csv(os.path.join(dataset_dir, 'pres_testing.csv'))\n",
    "df_no2 = pd.read_csv(os.path.join(dataset_dir, 'no2_testing.csv'))\n",
    "df_prec = pd.read_csv(os.path.join(dataset_dir, 'prec_testing.csv'))\n",
    "df_so = pd.read_csv(os.path.join(dataset_dir, 'so_testing.csv'))\n",
    "df_trends = pd.read_csv(os.path.join(dataset_dir, 'goo_trends.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pm10 = pd.read_csv(\"H:/asthma/data/pm10_testing.csv\")\n",
    "#df_bc = pd.read_csv(\"H:/asthma/data/bc_testing.csv\")\n",
    "#df_ozone = pd.read_csv(\"H:/asthma/data/ozone_testing.csv\")\n",
    "#df_no = pd.read_csv(\"H:/asthma/data/no_testing.csv\")\n",
    "#df_uv = pd.read_csv(\"H:/asthma/data/uv_testing.csv\")\n",
    "#df_pm2 = pd.read_csv(\"H:/asthma/data/pm2_testing.csv\")\n",
    "#df_temp = pd.read_csv(\"H:/asthma/data/temp_testing.csv\")\n",
    "#df_wind = pd.read_csv(\"H:/asthma/data/wind_testing.csv\")\n",
    "#data_hosp = pd.read_csv(\"H:/asthma/data/hosp_withoutcbu_auck.csv\")\n",
    "#df_RH = pd.read_csv(\"H:/asthma/data/RH_testing.csv\")\n",
    "#df_pres = pd.read_csv(\"H:/asthma/data/pres_testing.csv\")\n",
    "#df_no2 = pd.read_csv(\"H:/asthma/data/no2_testing.csv\")\n",
    "#df_prec = pd.read_csv(\"H:/asthma/data/prec_testing.csv\")\n",
    "#df_so = pd.read_csv(\"H:/asthma/data/so_testing.csv\")\n",
    "#df_trends = pd.read_csv(\"H:/asthma/data/goo_trends.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_ozone\n",
    "right = df_bc\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_no\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_uv\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_pm2\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_pm10\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_temp\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_wind\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_RH\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_prec\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_pres\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_no2\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_trends\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hosp.rename(columns = {'Admit Date' : 'Date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = data_hosp\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['capped_ozone'] = df_f['capped_ozone'].shift(-2)\n",
    "df_f['capped_bc(370)'] = df_f['capped_bc(370)'].shift(-1)\n",
    "df_f['capped_bc(880)'] = df_f['capped_bc(880)'].shift(-1)\n",
    "df_f['capped_wind'] = df_f['capped_wind'].shift(-2)\n",
    "df_f['UVI'] = df_f['UVI'].shift(-3)\n",
    "df_f['avg_no_y'] = df_f['avg_no_y'].shift(0)\n",
    "df_f['avg_no_x'] = df_f['avg_no_x'].shift(-1)\n",
    "df_f['avg_pm'] = df_f['avg_pm'].shift(-7)\n",
    "df_f['avg PM'] = df_f['avg PM'].shift(-3)\n",
    "df_f['capped_pres'] = df_f['capped_pres'].shift(-3)\n",
    "df_f['Prec'] = df_f['Prec'].shift(0)\n",
    "df_f['capped_scale'] = df_f['capped_scale'].shift(0)\n",
    "df_f['avg_temp'] = df_f['avg_temp'].shift(-5)\n",
    "df_f['capped_Tair'] = df_f['capped_Tair'].shift(-1)\n",
    "df_f['capped_Twet'] = df_f['capped_Twet'].shift(-1)\n",
    "df_f['capped_Tdew'] = df_f['capped_Tdew'].shift(-1)\n",
    "df_f['capped_RH'] = df_f['capped_RH'].shift(-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df_f.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_f.drop(columns=['status', 'Date', 'scaled data', 'capped_Tair','capped_RH','avg_no_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df_f['status'].values.reshape(X.shape[0], 1)\n",
    "y = df_f['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_1 = 866\n",
    "pipe = SMOTE(sampling_strategy={1: count_class_1})\n",
    "X_sm, y_sm = pipe.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm = X_sm.drop(columns=['Daily counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([X_sm, y_sm], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot('avg_temp', 'UVI', result, fit_reg=False, col = 'status', hue = 'status')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.catplot(x=\"status\", y=\"UVI\", data= result)\n",
    "plot.set_xlabels('Class', fontsize=13) # not set_label\n",
    "plot.set_ylabels(fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_sm, y_sm, test_size=0.50, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)\n",
    "#df_f = sc.fit_transform(df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sknet = MLPClassifier(hidden_layer_sizes=(50, ), learning_rate_init=0.001, max_iter=100, random_state=1, alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    " 'hidden_layer_sizes': [(50), (120,80,40), (100,50,30)],\n",
    "'max_iter': [50, 100, 150],\n",
    " 'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(sknet, param_grid, n_jobs= -1, cv=5)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sknet = MLPClassifier(hidden_layer_sizes=(100, 50, 30), learning_rate_init=0.1, max_iter=150, random_state=1, alpha=0.05, activation= 'relu', solver= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sknet.fit(Xtrain, ytrain.ravel())\n",
    "print(sknet.score(Xtrain, ytrain))\n",
    "#preds_train = sknet.predict(Xtrain)\n",
    "ypred = sknet.predict(Xtest)\n",
    "ypredp1 = sknet.predict_proba(Xtest)\n",
    "\n",
    "#print(ypred)\n",
    "#print(sknet.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(ytest, ypred))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, ypred, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, ypred, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, ypred, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=None, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(Xtrain, ytrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = clf.predict(Xtest)\n",
    "y_train_pred_rf = clf.predict(Xtrain)\n",
    "ypredp2 = clf.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy\", metrics.accuracy_score(ytrain, y_train_pred_rf))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_rf))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_rf, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, y_pred_rf, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, y_pred_rf, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel = \"rbf\", probability=True,  C=170, gamma= 3.0)\n",
    "clf_svm.fit(Xtrain,ytrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf_svm.predict(Xtest)\n",
    "ypredp2 = clf_svm.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_svm))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_svm, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, y_pred_svm, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, y_pred_svm, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clas = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 5, n_estimators = 1000, min_child_weight= 1, gamma = 0, nthread=4, seed = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clas.fit(Xtrain, ytrain.ravel(), eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_train = xg_clas.predict(Xtrain)\n",
    "y_pred_xgb = xg_clas.predict(Xtest)\n",
    "y_predprob_xgb_train = xg_clas.predict_proba(Xtrain)[:,1]\n",
    "y_predprob_xgb = xg_clas.predict_proba(Xtest)[:,1]\n",
    "ypredp3 = xg_clas.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_xgb))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_xgb, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, y_pred_xgb, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, y_pred_xgb, average = \"weighted\"))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytrain, y_predprob_xgb_train))\n",
    "print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(ytest, y_predprob_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
