{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import where\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "import scipy\n",
    "import sklearn\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn import linear_model\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE\n",
    "from scipy import stats\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import smote_variants as sv\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm10 = pd.read_csv(os.path.join(dataset_dir, 'pm10_testing.csv'))\n",
    "df_bc = pd.read_csv(os.path.join(dataset_dir, 'bc_testing.csv'))\n",
    "df_ozone = pd.read_csv(os.path.join(dataset_dir, 'ozone_testing.csv'))\n",
    "df_no = pd.read_csv(os.path.join(dataset_dir, 'no_testing.csv'))\n",
    "df_uv = pd.read_csv(os.path.join(dataset_dir, 'uv_testing.csv'))\n",
    "df_pm2 = pd.read_csv(os.path.join(dataset_dir, 'pm2_testing.csv'))\n",
    "df_temp = pd.read_csv(os.path.join(dataset_dir, 'temp_testing.csv'))\n",
    "df_wind = pd.read_csv(os.path.join(dataset_dir, 'wind_testing.csv'))\n",
    "data_hosp = pd.read_csv(os.path.join(dataset_dir, 'hosp_withoutcbu_auck.csv'))\n",
    "df_RH = pd.read_csv(os.path.join(dataset_dir, 'RH_testing.csv'))\n",
    "df_pres = pd.read_csv(os.path.join(dataset_dir, 'pres_testing.csv'))\n",
    "df_no2 = pd.read_csv(os.path.join(dataset_dir, 'no2_testing.csv'))\n",
    "df_prec = pd.read_csv(os.path.join(dataset_dir, 'prec_testing.csv'))\n",
    "df_so = pd.read_csv(os.path.join(dataset_dir, 'so_testing.csv'))\n",
    "df_trends = pd.read_csv(os.path.join(dataset_dir, 'goo_trends.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pm10 = pd.read_csv(\"H:/asthma/data/pm10_testing.csv\")\n",
    "#df_bc = pd.read_csv(\"H:/asthma/data/bc_testing.csv\")\n",
    "#df_ozone = pd.read_csv(\"H:/asthma/data/ozone_testing.csv\")\n",
    "#df_no = pd.read_csv(\"H:/asthma/data/no_testing.csv\")\n",
    "#df_uv = pd.read_csv(\"H:/asthma/data/uv_testing.csv\")\n",
    "#df_pm2 = pd.read_csv(\"H:/asthma/data/pm2_testing.csv\")\n",
    "#df_temp = pd.read_csv(\"H:/asthma/data/temp_testing.csv\")\n",
    "#df_wind = pd.read_csv(\"H:/asthma/data/wind_testing.csv\")\n",
    "#data_hosp = pd.read_csv(\"H:/asthma/data/hosp_withoutcbu_auck.csv\")\n",
    "#df_RH = pd.read_csv(\"H:/asthma/data/RH_testing.csv\")\n",
    "#df_pres = pd.read_csv(\"H:/asthma/data/pres_testing.csv\")\n",
    "#df_no2 = pd.read_csv(\"H:/asthma/data/no2_testing.csv\")\n",
    "#df_prec = pd.read_csv(\"H:/asthma/data/prec_testing.csv\")\n",
    "#df_so = pd.read_csv(\"H:/asthma/data/so_testing.csv\")\n",
    "#df_trends = pd.read_csv(\"H:/asthma/data/goo_trends.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_ozone\n",
    "right = df_bc\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_no\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_uv\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_pm2\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_pm10\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_temp\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_wind\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_RH\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_prec\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_pres\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_no2\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = df_trends\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hosp.rename(columns = {'Admit Date' : 'Date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df_f\n",
    "right = data_hosp\n",
    "#left['Date(NZST)'] = pd.to_datetime(left[\"Date(NZST)\"])\n",
    "#right['Date(NZST)'] = pd.to_datetime(right[\"Date(NZST)\"])\n",
    "df_f = pd.merge(left, right, on=[\"Date\"], how= \"outer\", validate=\"one_to_one\").sort_values(by = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"oz\" + \" \" + str(pearsonr(df_f['capped_ozone'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"bc370\" + \" \" + str(pearsonr(df_f['capped_bc(370)'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"bc880\" + \" \" + str(pearsonr(df_f['capped_bc(880)'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"wind\" + \" \" + str(pearsonr(df_f['capped_wind'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"uvi\" + \" \" + str(pearsonr(df_f['UVI'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"no2\" + \" \" + str(pearsonr(df_f['avg_no_y'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"nox\" + \" \" + str(pearsonr(df_f['avg_no_x'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"pm10\" + \" \" + str(pearsonr(df_f['avg_pm'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"pm2\" + \" \" + str(pearsonr(df_f['avg PM'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"pres\" + \" \" + str(pearsonr(df_f['capped_pres'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"prec\" + \" \" + str(pearsonr(df_f['Prec'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"temp\" + \" \" + str(pearsonr(df_f['avg_temp'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"Tair\" + \" \" + str(pearsonr(df_f['capped_Tair'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"Twet\" + \" \" + str(pearsonr(df_f['capped_Twet'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"Tdew\" + \" \" + str(pearsonr(df_f['capped_Tdew'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"RH\" + \" \" + str(pearsonr(df_f['capped_RH'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"trends\" + \" \" + str(pearsonr(df_f['capped_scale'],df_f['scaled data'])[0].round(decimals = 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['capped_ozone'] = df_f['capped_ozone'].shift(-2)\n",
    "df_f['capped_bc(370)'] = df_f['capped_bc(370)'].shift(-1)\n",
    "df_f['capped_bc(880)'] = df_f['capped_bc(880)'].shift(-1)\n",
    "df_f['capped_wind'] = df_f['capped_wind'].shift(-2)\n",
    "df_f['UVI'] = df_f['UVI'].shift(-3)\n",
    "df_f['avg_no_y'] = df_f['avg_no_y'].shift(0)\n",
    "df_f['avg_no_x'] = df_f['avg_no_x'].shift(-1)\n",
    "df_f['avg_pm'] = df_f['avg_pm'].shift(-7)\n",
    "df_f['avg PM'] = df_f['avg PM'].shift(-3)\n",
    "df_f['capped_pres'] = df_f['capped_pres'].shift(-3)\n",
    "df_f['Prec'] = df_f['Prec'].shift(0)\n",
    "df_f['capped_scale'] = df_f['capped_scale'].shift(0)\n",
    "df_f['avg_temp'] = df_f['avg_temp'].shift(-5)\n",
    "df_f['capped_Tair'] = df_f['capped_Tair'].shift(-1)\n",
    "df_f['capped_Twet'] = df_f['capped_Twet'].shift(-1)\n",
    "df_f['capped_Tdew'] = df_f['capped_Tdew'].shift(-1)\n",
    "df_f['capped_RH'] = df_f['capped_RH'].shift(-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df_f.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"oz\" + \" \" + str(pearsonr(df_f['capped_ozone'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"bc370\" + \" \" + str(pearsonr(df_f['capped_bc(370)'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"bc880\" + \" \" + str(pearsonr(df_f['capped_bc(880)'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"wind\" + \" \" + str(pearsonr(df_f['capped_wind'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"uvi\" + \" \" + str(pearsonr(df_f['UVI'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"no2\" + \" \" + str(pearsonr(df_f['avg_no_y'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"nox\" + \" \" + str(pearsonr(df_f['avg_no_x'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"pm10\" + \" \" + str(pearsonr(df_f['avg_pm'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"pm2\" + \" \" + str(pearsonr(df_f['avg PM'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"pres\" + \" \" + str(pearsonr(df_f['capped_pres'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"prec\" + \" \" + str(pearsonr(df_f['Prec'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"temp\" + \" \" + str(pearsonr(df_f['avg_temp'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"Tair\" + \" \" + str(pearsonr(df_f['capped_Tair'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"Twet\" + \" \" + str(pearsonr(df_f['capped_Twet'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"Tdew\" + \" \" + str(pearsonr(df_f['capped_Tdew'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"RH\" + \" \" + str(pearsonr(df_f['capped_RH'],df_f['scaled data'])[0].round(decimals = 4)))\n",
    "print(\"trends\" + \" \" + str(pearsonr(df_f['capped_scale'],df_f['scaled data'])[0].round(decimals = 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_f.to_csv('H:/asthma/data/asthma_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_f = df_f.drop(columns=['Daily counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_0, class_count_1 = df_f['status'].value_counts()\n",
    "\n",
    "# Separate class\n",
    "class_0 = df_f[df_f['status'] == 0]\n",
    "class_1 = df_f[df_f['status'] == 1]# print the shape of the class\n",
    "print('class 0:', class_0.shape)\n",
    "print('class 1:', class_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_over = class_1.sample(866, replace=True)\n",
    "\n",
    "df_f_equal = pd.concat([class_1_over, class_0], axis=0)\n",
    "df_f_equal['status'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_equal['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_equal['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_f_equal.drop(columns=['status', 'Date', 'Daily counts', 'scaled data', 'capped_Tair','capped_RH','avg_no_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_f_equal['status'].values.reshape(X.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_equal['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot('avg_temp', 'UVI', df_f_equal, hue='status', fit_reg=False, col = 'status')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.catplot(x=\"status\", y=\"UVI\", data= df_f_equal)\n",
    "plot.set_xlabels('Class', fontsize=13) # not set_label\n",
    "plot.set_ylabels(fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.50, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)\n",
    "#df_f = sc.fit_transform(df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sknet = MLPClassifier(hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=100, random_state=1, alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    " 'hidden_layer_sizes': [(50), (120,80,40), (100,50,30)],\n",
    "'max_iter': [50, 100, 150],\n",
    " 'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(sknet, param_grid, n_jobs= -1, cv=5)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sknet = MLPClassifier(hidden_layer_sizes=(120, 80, 40), learning_rate_init=0.1, max_iter=150, random_state=1, alpha=0.0001, activation= 'relu', solver= 'sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sknet.fit(Xtrain, ytrain.ravel())\n",
    "print(sknet.score(Xtrain, ytrain))\n",
    "#preds_train = sknet.predict(Xtrain)\n",
    "ypred = sknet.predict(Xtest)\n",
    "ypredp1 = sknet.predict_proba(Xtest)\n",
    "\n",
    "#print(ypred)\n",
    "#print(sknet.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(ytest, ypred))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, ypred, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, ypred, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, ypred, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=None, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(Xtrain, ytrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = clf.predict(Xtest)\n",
    "y_train_pred_rf = clf.predict(Xtrain)\n",
    "ypredp2 = clf.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy\", metrics.accuracy_score(ytrain, y_train_pred_rf))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_rf))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_rf, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, y_pred_rf, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, y_pred_rf, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel = \"rbf\", probability=True,  C=170, gamma= 3.0)\n",
    "clf_svm.fit(Xtrain,ytrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_train = clf_svm.predict(Xtrain)\n",
    "y_pred_svm = clf_svm.predict(Xtest)\n",
    "ypredp2 = clf_svm.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_svm))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytrain, y_pred_svm_train))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_svm, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, y_pred_svm, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, y_pred_svm, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(ytest, ypredp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(ytest, ypredp2)\n",
    "auc = metrics.roc_auc_score(ytest, ypredp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(round(auc, 2)))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "collections.Counter(ytrain[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import learning_curve\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [300, 550, 866]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, validation_scores = learning_curve(estimator = clf_svm, X = X,y = y.ravel(), train_sizes =array([0.1, 0.33, 0.55, 0.78, 1.]), cv = 5, scoring = 'accuracy', shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training scores:\\n\\n', train_scores)\n",
    "print('\\n', '-' * 70) # separator to make the output easy to read\n",
    "print('\\nValidation scores:\\n\\n', validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "validation_mean = np.mean(validation_scores, axis=1)\n",
    "validation_std = np.std(validation_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, figsize=(6,6))\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, validation_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "#plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "#plt.fill_between(train_sizes, validation_mean - validation_std, validation_mean + validation_std, color=\"#DDDDDD\")\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clas = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.9, learning_rate = 0.1,\n",
    "                max_depth = 9, alpha = 5, n_estimators = 1000, min_child_weight= 1, gamma = 0, nthread=4, seed = 127, subsample=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clas.fit(Xtrain, ytrain.ravel(), eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_train = xg_clas.predict(Xtrain)\n",
    "y_pred_xgb = xg_clas.predict(Xtest)\n",
    "y_predprob_xgb_train = xg_clas.predict_proba(Xtrain)[:,1]\n",
    "y_predprob_xgb = xg_clas.predict_proba(Xtest)[:,1]\n",
    "ypredp3 = xg_clas.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_xgb))\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, y_pred_xgb, normalize = False))\n",
    "print(\"Precision\", metrics.precision_score(ytest, y_pred_xgb, average = \"weighted\"))\n",
    "print(\"Recall\", metrics.recall_score(ytest, y_pred_xgb, average = \"weighted\"))\n",
    "#print(\"Precision\", metrics.precision_score(ytest, y_pred_xgb))\n",
    "#print(\"Recall\", metrics.recall_score(ytest, y_pred_xgb))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytrain, y_predprob_xgb_train))\n",
    "print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(ytest, y_predprob_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_clas)\n",
    "plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeatures = X.columns\n",
    "dict_features = dict(enumerate(myfeatures))\n",
    "\n",
    "# feat importance with names f1,f2,...\n",
    "axsub = xgb.plot_importance(xg_clas)\n",
    "\n",
    "# get the original names back\n",
    "Text_yticklabels = list(axsub.get_yticklabels())\n",
    "dict_features = dict(enumerate(myfeatures))\n",
    "lst_yticklabels = [ Text_yticklabels[i].get_text().lstrip('f') for i in range(len(Text_yticklabels))]\n",
    "lst_yticklabels = [ dict_features[int(i)] for i in lst_yticklabels]\n",
    "\n",
    "axsub.set_yticklabels(lst_yticklabels)\n",
    "print(dict_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
